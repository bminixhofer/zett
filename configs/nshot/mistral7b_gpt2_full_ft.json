{
    "output_dir": "output5",
    "train_directory": "/mnt/disks/persist/train",
    "valid_directory": "/mnt/disks/persist/valid",
    "langs": "flan",
    "model_name_or_path": "mistralai/Mistral-7B-v0.1",
    "init_from_params": "bucket/models/v7_mistral_final",
    "target_tokenizer_name": "bucket/artifacts/madlad_final/gpt20001",
    "revision": "refs/pr/95",
    "backbone_training": "full",
    "loss": "clm",
    "n_embd": 4096,
    "n_token_subsample": 16384,
    "eval_steps": 50000,
    "save_steps": 5000,
    "logging_steps": 25,
    "identity_n_subsample": 16384,
    "identity_steps": 0,
    "random_warmup_steps": 0,
    "warmup_steps": [
        0
    ],
    "steps": 50000,
    "dtype": "bfloat16",
    "use_unigram_bias": true,
    "learning_rate": [
        3e-6
    ],
    "learning_rate_alpha": 1.0,
    "max_grad_norm": 0.1,
    "extra_valid_tokenizer_names": [
        "bucket/artifacts/madlad_final/gpt20001"
    ],
    "extra_valid_files": [
        "/mnt/disks/persist/valid/en.parquet"
    ],
    "extra_lang_codes": [
        "flan"
    ],
    "do_tokenizer_sampling": false,
    "hn_rescale_embeddings": true,
    "hn_surface_maxlen": 7,
    "tokenizer_sample_mean": 32768,
    "tokenizer_sample_max": 32768,
    "tokenizer_sample_std": 0,
    "tokenizer_batch_size": 2048,
    "weight_decay": 0.01,
    "adam_beta2": 0.95,
    "hn_model_name_or_path": "roberta-base",
    "tokenizer_noise_mean": 1e-5,
    "tokenizer_noise_std": 4,
    "hn_add_inter_token_attention": false,
    "hn_embed_target_priors": false,
    "hn_inter_token_attention_bias_by_priors": true,
    "hn_embed_using_source_embeddings": true,
    "train_batch_size": 32,
    "eval_batch_size": 32,
    "block_size": 512,
    "hn_num_attention_heads": 32,
    "hn_hidden_size": 4096,
    "hn_intermediate_size": 8192,
    "gradient_accumulation_steps": 1,
    "learnable_bias": false,
    "add_target_priors_to_bias": false,
    "do_sequence_packing": true,
    "overwrite_special_token_embeddings": false,
    "lexical_loss_kind": "mse",
    "apply_lexical_loss_to_init": true,
    "lexical_loss_weight": 0.5,
    "debug": false,
    "dataloader_num_workers": 8,
    "mix_languages": false
}